from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api import TranscriptsDisabled
from pytube import YouTube
from pytube import Channel
import scrapetube
import urllib.parse as urlparse
import concurrent.futures
import pandas as pd
import re
import requests


def video_id(value):
    """Parses the URL to pull out the video ID for the YouTube video
       from the following source: https://stackoverflow.com/questions/4356538/how-can-i-extract-video-id-from-youtubes-link-in-python

    Args:
        value (str): The url for the Youtube video

        Examples:
        - http://youtu.be/SA2iWivDJiE
        - http://www.youtube.com/watch?v=_oPAwA_Udwc&feature=feedu
        - http://www.youtube.com/embed/SA2iWivDJiE
        - http://www.youtube.com/v/SA2iWivDJiE?version=3&amp;hl=en_US

    Returns:
        The video ID parsed from the URL of a Youtube video
    """

    query = urlparse.urlparse(value)
    if query.hostname == 'youtu.be':
        return query.path[1:]
    if query.hostname in ('www.youtube.com', 'youtube.com'):
        if query.path == '/watch':
            p = urlparse.parse_qs(query.query)
            return p['v'][0]
        if query.path[:7] == '/embed/':
            return query.path.split('/')[2]
        if query.path[:3] == '/v/':
            return query.path.split('/')[2]
    
    # fail?
    return None


def search_video(video_tag, search_keyword):
    """Performs a keyword search of YouTube's autogenerated transcripts used for closed captioning

    Args:
        video_tag (str): The video ID parsed from the URL of a Youtube video
        search_keyword (str): User input representing the keyword to be searched for

    Returns:
        df_html (string): The html version of a dataframe with columns for occurence time, timestamp URL's,
            and text matching the keyword
        count (int): A counter representing the number of times the keyword was found in the video
    """

    count = 0
    df_html = ""
    link = 'https://youtu.be/'

    # Define column names
    columns = ["Occurence Time (seconds)", "Timestamp URL", "Transcript Text"]

    # Create a list that will store the intermediate data frame rows
    data = []

    try:
        transcript_list = YouTubeTranscriptApi.list_transcripts(video_tag)

        # iterate over all available transcripts
        for transcript in transcript_list:
            result = [video_slice for video_slice in transcript.fetch() if search_keyword.lower() in video_slice['text'].lower()]
            
            if (len(result) == 0):
                # print("\nNo matches found for keyword: " + search_keyword)
                
                return df_html, count

            #Generate the timestamp links where the keyword was found in the video
            for item in result:
                timestamp_url = f'{link}{video_tag}?t={item["start"] - 1}s'

                data.append([str(item['start']), timestamp_url, item['text']])
            
        # Create a DataFrame
        search_results = pd.DataFrame(data, columns=columns)
        search_results.columns.name = 'Instance'
        search_results.index.name = None
        search_results.index += 1   # Starts the count at 1 instead of the default of zero
        count = len(search_results.index)

        # Convert DataFrame to HTML table
        df_html = search_results.to_html(index= True, escape= False, render_links=True, classes='table table-bordered w3-table-all w3-card-4 table-striped', justify='center')

        return df_html, count

    except TranscriptsDisabled:
        print("Subtitles are disabled for this video. Unable to search for keyword")

        return df_html, count


# TODO: Add in error handling here
def get_channel_id(channel_url):
    """Scrapes the page source requested using the channel URL to glean the channel ID

    Args:
        channel_url (str): The url for a given Youtube Channel

        Examples:
        - https://www.youtube.com/c/{channel_name}/
        - https://www.youtube.com/channel/{channel_id}/
        - https://www.youtube.com/@{channel_name}/

    Returns:
        The channel ID scraped from the page source of the channel URL
    """

    response = requests.get(channel_url)
    page_source = response.text

    channel_id_match = re.search(r'canonical" href="https://www.youtube.com/channel/([^"]+)', page_source)
    if channel_id_match:
        channel_id = channel_id_match.group(1)
        print("Channel ID:", channel_id)
    else:
        print("Channel ID not found.")
        channel_id = None

    return channel_id


# Search an entire channel for a keyword
def search_channel(channel_url, search_keyword):
    """Performs a keyword search over all videos in contained in a Youtube Channel
       using YouTube's autogenerated transcripts

    Args:
        channel_url (str): The url for a given Youtube Channel
        
        Examples:
        - https://www.youtube.com/c/{channel_name}/
        - https://www.youtube.com/channel/{channel_id}/
        - https://www.youtube.com/@{channel_name}/

        search_keyword (str): User input representing the keyword to be searched for

    Returns:
        df_list (List[string]): A list containing the html version of dataframes from each video where the keyword was found.
            The dataframe has columns for occurence time, timestamp URL's, and text matching the keyword
        count_list (List[int]): A list containing counter values which represent the number of times the keyword was found 
        in each video from the channel
    """

    channel_id = get_channel_id(channel_url)
    formatted_channel_url = 'https://youtube.com/channel/' + channel_id
    c = Channel(formatted_channel_url)
    channel_name = c.channel_name 
    # print("This is the channel ID: " + channel_id)
    # print("This is the channel name: " + channel_name)

    videos = scrapetube.get_channel(c.channel_id)
    df_list = []
    video_titles = []
    count_list = []

    def process_video(video):
        video_tag = video['videoId']
        search_results, keyword_count = search_video(video_tag, search_keyword)
        link = 'https://youtu.be/'
        # video_url= link + video_tag
        video_url = f'{link}{video_tag}'
        yt = YouTube(video_url)

        if search_results != "" and search_results != None:
            df_list.append(search_results)
            video_titles.append(yt.title)
            count_list.append(keyword_count)
    
    with concurrent.futures.ThreadPoolExecutor() as executor:
        executor.map(process_video, videos)

    if not count_list:
        count_list.append(0)

    return df_list, video_titles, count_list, channel_name